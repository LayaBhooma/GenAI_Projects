{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b22969fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pymilvus in c:\\users\\nirma\\training\\genai_projects\\.venv\\lib\\site-packages (2.6.7)\n",
      "Requirement already satisfied: setuptools>69 in c:\\users\\nirma\\training\\genai_projects\\.venv\\lib\\site-packages (from pymilvus) (80.10.1)\n",
      "Requirement already satisfied: grpcio!=1.68.0,!=1.68.1,!=1.69.0,!=1.70.0,!=1.70.1,!=1.71.0,!=1.72.1,!=1.73.0,>=1.66.2 in c:\\users\\nirma\\training\\genai_projects\\.venv\\lib\\site-packages (from pymilvus) (1.76.0)\n",
      "Requirement already satisfied: orjson>=3.10.15 in c:\\users\\nirma\\training\\genai_projects\\.venv\\lib\\site-packages (from pymilvus) (3.11.5)\n",
      "Requirement already satisfied: protobuf>=5.27.2 in c:\\users\\nirma\\training\\genai_projects\\.venv\\lib\\site-packages (from pymilvus) (6.33.4)\n",
      "Requirement already satisfied: python-dotenv<2.0.0,>=1.0.1 in c:\\users\\nirma\\training\\genai_projects\\.venv\\lib\\site-packages (from pymilvus) (1.2.1)\n",
      "Requirement already satisfied: pandas>=1.2.4 in c:\\users\\nirma\\training\\genai_projects\\.venv\\lib\\site-packages (from pymilvus) (2.3.3)\n",
      "Requirement already satisfied: cachetools>=5.0.0 in c:\\users\\nirma\\training\\genai_projects\\.venv\\lib\\site-packages (from pymilvus) (6.2.6)\n",
      "Requirement already satisfied: typing-extensions~=4.12 in c:\\users\\nirma\\training\\genai_projects\\.venv\\lib\\site-packages (from grpcio!=1.68.0,!=1.68.1,!=1.69.0,!=1.70.0,!=1.70.1,!=1.71.0,!=1.72.1,!=1.73.0,>=1.66.2->pymilvus) (4.15.0)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\nirma\\training\\genai_projects\\.venv\\lib\\site-packages (from pandas>=1.2.4->pymilvus) (2.3.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\nirma\\training\\genai_projects\\.venv\\lib\\site-packages (from pandas>=1.2.4->pymilvus) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\nirma\\training\\genai_projects\\.venv\\lib\\site-packages (from pandas>=1.2.4->pymilvus) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\nirma\\training\\genai_projects\\.venv\\lib\\site-packages (from pandas>=1.2.4->pymilvus) (2025.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\nirma\\training\\genai_projects\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas>=1.2.4->pymilvus) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pymilvus\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b7399602",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(override=True, dotenv_path=\"../.env.local\")\n",
    "\n",
    "from docx import Document\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "my_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fab68053",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to Milvus on Zilliz Cloud\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'auto_id': False, 'description': 'Policy documents with embeddings', 'fields': [{'name': 'doc_id', 'description': '', 'type': <DataType.INT64: 5>, 'is_primary': True, 'auto_id': False}, {'name': 'title', 'description': '', 'type': <DataType.VARCHAR: 21>, 'params': {'max_length': 200}}, {'name': 'domain', 'description': '', 'type': <DataType.VARCHAR: 21>, 'params': {'max_length': 100}}, {'name': 'content', 'description': '', 'type': <DataType.VARCHAR: 21>, 'params': {'max_length': 2500}}, {'name': 'embedding', 'description': '', 'type': <DataType.FLOAT_VECTOR: 101>, 'params': {'dim': 384}}], 'enable_dynamic_field': False, 'enable_namespace': False}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Connect to  Milvus.\n",
    "from pymilvus import MilvusClient\n",
    "from pymilvus import connections\n",
    "\n",
    "# 1. Configuration\n",
    "load_dotenv(override=True, dotenv_path=\"../.env.local\")\n",
    "\n",
    "milvus_uri = os.getenv(\"MILVUS_URI\")\n",
    "milvus_token = os.getenv(\"MILVUS_API_KEY\")\n",
    "\n",
    "milvus_conn = connections.connect(\n",
    "    alias=\"default\",\n",
    "    uri=milvus_uri,\n",
    "    token=milvus_token\n",
    ")\n",
    "\n",
    "print(\"Connected to Milvus on Zilliz Cloud\")\n",
    "\n",
    "from pymilvus import Collection\n",
    "\n",
    "collection = Collection(\"policy_docs_collection\")\n",
    "collection.load()\n",
    "\n",
    "collection.schema\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f13f2bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepared: Customer_Journey_Map.docx\n",
      "Prepared: Privacy_Policy.docx\n",
      "Prepared: Terms_ And_Conditions.docx\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "from docx import Document\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from pymilvus import Collection\n",
    "\n",
    "# 1. Setup\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "data_dir = './documents'\n",
    "docx_files = [f for f in os.listdir(data_dir) if f.endswith('.docx')][:3]\n",
    "\n",
    "# 2. Prepare column-wise lists\n",
    "data_to_insert = []\n",
    "\n",
    "for i, filename in enumerate(docx_files):\n",
    "    file_path = os.path.join(data_dir, filename)\n",
    "    try:\n",
    "        doc = Document(file_path)\n",
    "        full_text = \" \".join([p.text for p in doc.paragraphs if p.text.strip()])\n",
    "        \n",
    "        if full_text:\n",
    "            vector = model.encode(full_text).tolist()\n",
    "            \n",
    "            # Create a dictionary matching your EXACT schema field names\n",
    "            entity = {\n",
    "                \"doc_id\": int(time.time() + i),  # PK\n",
    "                \"embedding\": vector,             # FLOAT_VECTOR\n",
    "                \"title\": filename[:200],         # VARCHAR\n",
    "                \"domain\": \"Policy\",              # VARCHAR\n",
    "                \"content\": full_text[:2000]      # VARCHAR\n",
    "            }\n",
    "            data_to_insert.append(entity)\n",
    "            print(f\"Prepared: {filename}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d8cfef4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success! Inserted 3 records.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 3. Insert into Collection\n",
    "if data_to_insert:\n",
    "    try:\n",
    "        # In this version, we pass the list of dictionaries directly\n",
    "        res = collection.insert(data_to_insert)\n",
    "        print(f\"Success! Inserted {res.insert_count} records.\")\n",
    "        \n",
    "        # Make it searchable\n",
    "        collection.flush()\n",
    "    except Exception as e:\n",
    "        print(f\"Insertion Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d920a729",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Search Results for: 'Are SpeakEQ terms and conditions reasonable? Are they standard across mobile apps?' ---\n",
      "\n",
      "Rank: 1 | Score: 0.6848\n",
      "Source File: Terms_ And_Conditions.docx\n",
      "Snippet: Terms & Conditions Welcome to SpeakEQ! These Terms & Conditions (\"Terms\") explain the rules for using the SpeakEQ mobile appprovided by Yellow Sapphire Consulting, located in Washington, USA. ownloading and using  to these Terms.   Account\n",
      " Voice Recordings and Data  voice recordings, audio files, a...\n",
      "------------------------------\n",
      "\n",
      "Rank: 1 | Score: 0.6848\n",
      "Source File: Terms_ And_Conditions.docx\n",
      "Snippet: Terms & Conditions Welcome to SpeakEQ! These Terms & Conditions (\"Terms\") explain the rules for using the SpeakEQ mobile appprovided by Yellow Sapphire Consulting, located in Washington, USA. ownloading and using  to these Terms.   Account\n",
      " Voice Recordings and Data  voice recordings, audio files, a...\n",
      "------------------------------\n",
      "rag_result: Terms & Conditions Welcome to SpeakEQ! These Terms & Conditions (\"Terms\") explain the rules for using the SpeakEQ mobile appprovided by Yellow Sapphire Consulting, located in Washington, USA. ownloading and using  to these Terms.   Account\n",
      " Voice Recordings and Data  voice recordings, audio files, and other content belong to . By using , give permission to: Analyze and process recordings to provide insights Store data securely so can access it anytime Use voice data to train and improve emotion recognition technology Keep data encrypted and protected Subscription and Payment Free and Paid Features\n",
      "offers both free features and premium services. Prices are shown in  and charged in US dollars. Auto-Renewal\n",
      "If subscribe, subscription automatically renews unless cancel before the renewal date. can cancel anytime in account settings or through device's app store. Refunds\n",
      "Subscription fees are generally non-refundable but consider on a case-by-case basis.  support@speakeq.. Payment Processing\n",
      "Payments are handled securely . store full payment card information. Technology and Content , including software, algorithms, design, and branding, belongs to  Disclaimers Not Professional Adviceprovides insights for personal development and self-awareness. It not a substitute for professional therapy, medical advice, or counseling. If need professional help, please consult a qualified professional. AccuracyWhile  recognition technology is sophisticated, it   accurate. Many factors can affect results, and  should be used as one tool among many for understanding communication. Service Availability  may occasionally be unavailable guarantee will always work perfectly. Liability Limits To the extent permitted by law: total liability to is limited to the amount paid in the  not liable for issues caused by factors outside control Complete Agreementhese Terms and Privacy Policy make up the complete agreement between and  . Contact Us Questions about these Terms? We're here to help: Yellow \n",
      "\n",
      "Terms & Conditions Welcome to SpeakEQ! These Terms & Conditions (\"Terms\") explain the rules for using the SpeakEQ mobile appprovided by Yellow Sapphire Consulting, located in Washington, USA. ownloading and using  to these Terms.   Account\n",
      " Voice Recordings and Data  voice recordings, audio files, and other content belong to . By using , give permission to: Analyze and process recordings to provide insights Store data securely so can access it anytime Use voice data to train and improve emotion recognition technology Keep data encrypted and protected Subscription and Payment Free and Paid Features\n",
      "offers both free features and premium services. Prices are shown in  and charged in US dollars. Auto-Renewal\n",
      "If subscribe, subscription automatically renews unless cancel before the renewal date. can cancel anytime in account settings or through device's app store. Refunds\n",
      "Subscription fees are generally non-refundable but consider on a case-by-case basis.  support@speakeq.. Payment Processing\n",
      "Payments are handled securely . store full payment card information. Technology and Content , including software, algorithms, design, and branding, belongs to  Disclaimers Not Professional Adviceprovides insights for personal development and self-awareness. It not a substitute for professional therapy, medical advice, or counseling. If need professional help, please consult a qualified professional. AccuracyWhile  recognition technology is sophisticated, it   accurate. Many factors can affect results, and  should be used as one tool among many for understanding communication. Service Availability  may occasionally be unavailable guarantee will always work perfectly. Liability Limits To the extent permitted by law: total liability to is limited to the amount paid in the  not liable for issues caused by factors outside control Complete Agreementhese Terms and Privacy Policy make up the complete agreement between and  . Contact Us Questions about these Terms? We're here to help: Yellow \n"
     ]
    }
   ],
   "source": [
    "# Write a query function that takes a user question, retrieves the top 3 most similar chunks, and prints them.\n",
    "\n",
    "def query_policy_docs(question):\n",
    "    # 1. Convert question to embedding\n",
    "    question_embedding = model.encode(question).tolist()\n",
    "\n",
    "    # 2. Define search parameters\n",
    "    search_params = {\n",
    "        \"metric_type\": \"COSINE\", # Use COSINE or L2 based on your index\n",
    "        \"params\": {\"nprobe\": 10},\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        # 3. Perform the search\n",
    "        # We explicitly request the 'title' and 'content' fields to be returned\n",
    "        results = collection.search(\n",
    "            data=[question_embedding], \n",
    "            anns_field=\"embedding\", \n",
    "            param=search_params,\n",
    "            limit=3,\n",
    "            output_fields=[\"title\", \"content\"]\n",
    "        )\n",
    "        \n",
    "        # 4. Print the results\n",
    "        print(f\"\\n--- Search Results for: '{question}' ---\")\n",
    "        all_contents = []\n",
    "        for i, hits in enumerate(results):\n",
    "            for hit in hits:\n",
    "                content = hit.entity.get('content')\n",
    "                all_contents.append(content) # Store for RAG context\n",
    "                print(f\"\\nRank: {i+1} | Score: {hit.score:.4f}\")\n",
    "                print(f\"Source File: {hit.entity.get('title')}\")\n",
    "                print(f\"Snippet: {hit.entity.get('content')[:300]}...\") # Print first 300 chars\n",
    "                print(\"-\" * 30)\n",
    "                           \n",
    "        # Join all retrieved chunks into one string\n",
    "        return \"\\n\\n\".join(all_contents)\n",
    "    except Exception as e:\n",
    "        print(f\"Search Error: {e}\")\n",
    "\n",
    "# --- Example Usage ---\n",
    "# Ensure the collection is loaded before searching\n",
    "collection.load()\n",
    "\n",
    "user_query = \"Are SpeakEQ terms and conditions reasonable? Are they standard across mobile apps?\"\n",
    "rag_result = query_policy_docs(user_query)\n",
    "print(f\"rag_result: {rag_result}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "91a06c82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AI ANSWER:\n",
      "I don't know based on internal docs. The provided context does not specifically evaluate the reasonableness or standard nature of SpeakEQ's terms and conditions compared to other mobile apps. It only details the terms themselves.\n",
      "\n",
      "SOURCES USED: ['Terms_ And_Conditions.docx']\n"
     ]
    }
   ],
   "source": [
    "# Pass the retrieved context to an OpenAI model (or a local LLM) and generate an answer.\n",
    "\n",
    "\n",
    "client = OpenAI(api_key=my_api_key)\n",
    "\n",
    "\n",
    "def generate_rag_answer(question):\n",
    "    # 2. Get the context from your existing Milvus query function\n",
    "    # (Assuming query_policy_docs returns the text chunks)\n",
    "    question_embedding = model.encode(question).tolist()\n",
    "    \n",
    "    results = collection.search(\n",
    "        data=[question_embedding], \n",
    "        anns_field=\"embedding\", \n",
    "        param={\"metric_type\": \"COSINE\", \"params\": {\"nprobe\": 10}},\n",
    "        limit=3,\n",
    "        output_fields=[\"content\", \"title\"]\n",
    "    )\n",
    "\n",
    "    # 3. Combine retrieved chunks into a single context string\n",
    "    retrieved_context = \"\"\n",
    "    sources = []\n",
    "    for hit in results[0]:\n",
    "        retrieved_context += f\"\\nSource ({hit.entity.get('title')}): {hit.entity.get('content')}\\n\"\n",
    "        sources.append(hit.entity.get('title'))\n",
    "\n",
    "    # 4. Create the System Prompt\n",
    "    system_prompt = \"\"\"\n",
    "    You are a helpful assistant. Use the provided context from our internal  \n",
    "    documents to answer the user's question. If the answer is not in the context, \n",
    "    say you don't know based on internal docs. Do not use outside knowledge.\n",
    "    \"\"\"\n",
    "\n",
    "    user_prompt = f\"Context: {retrieved_context}\\n\\nQuestion: {question}\"\n",
    "\n",
    "    # 5. Generate Answer via OpenAI\n",
    "    response = client.chat.completions.create( \n",
    "    model=\"gpt-4o\", \n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_prompt}\n",
    "    ]\n",
    ")\n",
    "\n",
    "    return response.choices[0].message.content, sources\n",
    "\n",
    "# --- Execution ---\n",
    "query = \"Are SpeakEQ terms and conditions reasonable? Are they standard across mobile apps?\"\n",
    "answer, source_files = generate_rag_answer(query)\n",
    "\n",
    "print(f\"\\nAI ANSWER:\\n{answer}\")\n",
    "print(f\"\\nSOURCES USED: {list(set(source_files))}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e3394b26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_query: Are SpeakEQ terms and conditions reasonable? Are they standard across mobile apps?\n",
      "context_used: ['Terms_ And_Conditions.docx', 'Terms_ And_Conditions.docx']\n",
      "rag_answer: The context provided does not explicitly state whether the terms and conditions of SpeakEQ are reasonable or how they compare to terms of other mobile apps. However, the terms include standard elements such as voice data handling, subscription management, non-liability clauses, and a disclaimer that the service is not a substitute for professional advice, which are common in mobile app agreements. For a determination of reasonableness or a comparison to industry standards, further analysis or comparison would be necessary, which is not available in the provided context.\n",
      "ai_search_answer: To evaluate if the terms and conditions of SpeakEQ are reasonable, we would need to look at the specific content of those terms. However, I can provide you with some general guidance on assessing their reasonableness and standard nature compared to other mobile apps:\n",
      "\n",
      "1. **Data Privacy:** Check how SpeakEQ handles user data. Are they collecting more information than necessary? Do they clearly state how your data will be used and if it will be shared with third parties? It is standard for apps to collect some user data, but it should be limited to what is necessary for the app's functionality.\n",
      "\n",
      "2. **User Consent:** Look for how the app obtains user consent, especially regarding data collection and notifications. It's reasonable and standard for apps to require explicit consent for data collection.\n",
      "\n",
      "3. **Liability and Warranty Disclaimers:** Most apps include disclaimers that limit the developer's liability for issues arising from the use of the app. Compare these disclaimers to those of other similar apps to judge if they’re balanced.\n",
      "\n",
      "4. **Subscription and Payment Terms:** If SpeakEQ has any in-app purchases or subscription models, check the transparency of these terms. Are you clearly informed about pricing, automatic renewals, and cancellation policies? Transparent pricing terms are a standard and necessary practice.\n",
      "\n",
      "5. **Modification of Terms:** Many apps reserve the right to change their terms and conditions. It’s reasonable if they commit to notifying users of significant changes and ideally offer a way to accept or decline new terms.\n",
      "\n",
      "6. **Governing Law and Dispute Resolution:** These clauses dictate how disputes are resolved and under which jurisdiction. It's common to see clauses detailing arbitration or specific governing laws, and their reasonableness often depends on whether they unfairly favor the company.\n",
      "\n",
      "To determine if SpeakEQ's terms and conditions are standard or reasonable, you would need to read through these specific elements within their document and, if possible, compare them to those of other similar apps, focusing on user rights and protections. Consulting legal expertise can also provide more clarity on what is considered standard and reasonable in the industry.\n",
      "verdict: To evaluate the two answers based on the provided criteria:\n",
      "\n",
      "1. **Grounding:**\n",
      "   - **Answer A** stays grounded in the context by acknowledging that the provided document does not explicitly state whether the terms and conditions of SpeakEQ are reasonable or how they compare to other mobile apps. It mentions standard elements typically found in mobile app agreements but does not make any claims beyond what is stated in the context.\n",
      "   - **Answer B** provides a general guide on assessing terms and conditions but does not directly reference the specific content of the SpeakEQ terms and conditions from the context. It assumes certain elements that should be checked but does not confirm their presence in the document.\n",
      "\n",
      "2. **Hallucination:**\n",
      "   - **Answer A** does not hallucinate as it clearly states the limitations of the provided context and does not invent any facts about the terms and conditions.\n",
      "   - **Answer B** potentially hallucinates by suggesting specific elements to look for in the terms and conditions without confirming their presence in the provided document. It assumes a level of detail that is not confirmed by the context.\n",
      "\n",
      "3. **Accuracy:**\n",
      "   - **Answer A** is more accurate in terms of staying within the bounds of the provided context. It does not make assumptions about the content of the terms and conditions.\n",
      "   - **Answer B** offers a more detailed analysis of what to look for in terms and conditions but does so without direct reference to the specific document, which may lead to inaccuracies if those elements are not present.\n",
      "\n",
      "**Final Verdict:**\n",
      "Answer A is better because it remains grounded in the provided context, does not hallucinate by inventing details not found in the document, and accurately reflects the limitations of the information available. Answer B, while informative, assumes details not confirmed by the context, which could lead to inaccuracies.\n"
     ]
    }
   ],
   "source": [
    "def evaluate_results(query, milvus_context, rag_answer, ai_search_answer):\n",
    "    judge_prompt = f\"\"\"\n",
    "    You are an objective auditor. Your job is to compare two AI-generated answers based on the provided Context.\n",
    "    \n",
    "    USER QUERY: {query}\n",
    "    \n",
    "    INTERNAL DOCUMENT CONTEXT:\n",
    "    {milvus_context}\n",
    "    \n",
    "    ---\n",
    "    ANSWER A (RAG System): {rag_answer}\n",
    "    ---\n",
    "    ANSWER B (Standard AI Search): {ai_search_answer}\n",
    "    ---\n",
    "    \n",
    "    EVALUATION CRITERIA:\n",
    "    1. Grounding: Does the answer stay loyal to the Internal Context?\n",
    "    2. Hallucination: Does it invent facts not found in the context?\n",
    "    3. Accuracy: Which is more correct for this specific company?\n",
    "\n",
    "    Provide a final verdict on which is better and why.\n",
    "    \"\"\"\n",
    "\n",
    "    # Call the judge (using your client object)\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[{\"role\": \"system\", \"content\": judge_prompt}],\n",
    "        temperature=0\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# --- How to run the comparison ---\n",
    "# 1. Get RAG result (uses Milvus)\n",
    "rag_answer, context_used = generate_rag_answer(user_query)\n",
    "\n",
    "# 2. Get Standard AI result (no context provided)\n",
    "standard_response = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[{\"role\": \"user\", \"content\": user_query}]\n",
    ")\n",
    "ai_search_answer = standard_response.choices[0].message.content\n",
    "\n",
    "# 3. Run the Judge\n",
    "verdict = evaluate_results(\"user_query\", context_used, rag_answer, ai_search_answer)\n",
    "print(f\"user_query: {user_query}\")\n",
    "print(f\"context_used: {context_used}\")\n",
    "print(f\"rag_answer: {rag_answer}\")\n",
    "print(f\"ai_search_answer: {ai_search_answer}\")\n",
    "print(f\"verdict: {verdict}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
