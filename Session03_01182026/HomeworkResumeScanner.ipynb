{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b65a7ce8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: PDFPlumber in c:\\users\\nirma\\training\\genai_projects\\.venv\\lib\\site-packages (0.11.9)\n",
      "Requirement already satisfied: pdfminer.six==20251230 in c:\\users\\nirma\\training\\genai_projects\\.venv\\lib\\site-packages (from PDFPlumber) (20251230)\n",
      "Requirement already satisfied: Pillow>=9.1 in c:\\users\\nirma\\training\\genai_projects\\.venv\\lib\\site-packages (from PDFPlumber) (12.1.0)\n",
      "Requirement already satisfied: pypdfium2>=4.18.0 in c:\\users\\nirma\\training\\genai_projects\\.venv\\lib\\site-packages (from PDFPlumber) (5.3.0)\n",
      "Requirement already satisfied: charset-normalizer>=2.0.0 in c:\\users\\nirma\\training\\genai_projects\\.venv\\lib\\site-packages (from pdfminer.six==20251230->PDFPlumber) (3.4.4)\n",
      "Requirement already satisfied: cryptography>=36.0.0 in c:\\users\\nirma\\training\\genai_projects\\.venv\\lib\\site-packages (from pdfminer.six==20251230->PDFPlumber) (46.0.3)\n",
      "Requirement already satisfied: cffi>=2.0.0 in c:\\users\\nirma\\training\\genai_projects\\.venv\\lib\\site-packages (from cryptography>=36.0.0->pdfminer.six==20251230->PDFPlumber) (2.0.0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\nirma\\training\\genai_projects\\.venv\\lib\\site-packages (from cffi>=2.0.0->cryptography>=36.0.0->pdfminer.six==20251230->PDFPlumber) (2.23)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: openai in c:\\users\\nirma\\training\\genai_projects\\.venv\\lib\\site-packages (2.15.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\nirma\\training\\genai_projects\\.venv\\lib\\site-packages (from openai) (4.12.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\nirma\\training\\genai_projects\\.venv\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\nirma\\training\\genai_projects\\.venv\\lib\\site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.10.0 in c:\\users\\nirma\\training\\genai_projects\\.venv\\lib\\site-packages (from openai) (0.12.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\nirma\\training\\genai_projects\\.venv\\lib\\site-packages (from openai) (2.12.5)\n",
      "Requirement already satisfied: sniffio in c:\\users\\nirma\\training\\genai_projects\\.venv\\lib\\site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\nirma\\training\\genai_projects\\.venv\\lib\\site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\nirma\\training\\genai_projects\\.venv\\lib\\site-packages (from openai) (4.15.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\nirma\\training\\genai_projects\\.venv\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.11)\n",
      "Requirement already satisfied: certifi in c:\\users\\nirma\\training\\genai_projects\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2026.1.4)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\nirma\\training\\genai_projects\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\nirma\\training\\genai_projects\\.venv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\nirma\\training\\genai_projects\\.venv\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in c:\\users\\nirma\\training\\genai_projects\\.venv\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in c:\\users\\nirma\\training\\genai_projects\\.venv\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.4.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\nirma\\training\\genai_projects\\.venv\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install PDFPlumber \n",
    "%pip install openai\n",
    "#%pip install pandas ipython\n",
    "#%pip install os python-dotenv\n",
    "\n",
    "\n",
    "import pdfplumber\n",
    "import openai\n",
    "import pandas as pd \n",
    "from typing import List, Dict\n",
    "from IPython.display import display, Markdown\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f2ae4ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted Resume Text:\n",
      "Nirmala Kumar\n",
      "EXECUTIVE SUMMARY\n",
      "Transformational Product Leader and MIT-trained CTO with 20+ years of experience leading enterprise digital\n",
      "transformations and technical product delivery. Specialized in turning complex clinical and technical goals into\n",
      "reliable, scalable, compliant systems. Proven track record in architectural strategy and platform modernization\n",
      "for large-scale organizations (AT&T, Microsoft, Deloitte) and public sector entities. Currently Founder & CEO of\n",
      "SpeakEQ, leveraging hi\n"
     ]
    }
   ],
   "source": [
    "# Resume Summarization (PDF)\n",
    "# Choose a resume (any sample PDF).\n",
    "\n",
    "load_dotenv(override=True, dotenv_path=\"../.env.local\")\n",
    "\n",
    "# Initialize the client\n",
    "from openai import OpenAI\n",
    "my_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "client = OpenAI(api_key=my_api_key)\n",
    "\n",
    "# 1. Path to the local resume PDF\n",
    "file_name = \"./data/resume.pdf\"\n",
    "\n",
    "# 1. Open PDF Resume and Extract text from the PDF resume using PDFPlumber.\n",
    "def extract_text_from_pdf(doc):\n",
    "    with pdfplumber.open(doc) as pdf:\n",
    "        text = \"\"\n",
    "        for page in pdf.pages:\n",
    "            text += page.extract_text()\n",
    "        return text\n",
    "# Extract text from the resume\n",
    "resume_text = extract_text_from_pdf(file_name)\n",
    "print(\"Extracted Resume Text:\")\n",
    "print(resume_text[:500])  # Print first 500 characters of the resume text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "119f856d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Define a function to extract key information using OpenAI GPT.\n",
    "from urllib import response\n",
    "from openai import OpenAI\n",
    "\n",
    "def analyze_resume_using_gpt(resume_text):\n",
    "    # Added triple quotes for a multi-line string and fixed the f-string syntax\n",
    "    prompt = f\"\"\"\n",
    "    Extract the following information from the resume text:\n",
    "    1. Candidate name\n",
    "    2. Years of experience\n",
    "    3. Skill set\n",
    "    4. Education summary\n",
    "    5. Generate a concise professional summary\n",
    "    Resume Text: {resume_text}\n",
    "\"\"\"\n",
    "    client = OpenAI()\n",
    "\n",
    "    # Using the modern Responses API for GPT-5\n",
    "    response = client.chat.completions.create(\n",
    "            model=\"gpt-5-nano\", \n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a resume optimization expert, specializing in authentic, strategic positioning of candidate experience. Your role is to analyze resumes against job descriptions to identify strengths, gaps, and keywords, ensuring content remains genuine and impactful for Applicant Tracking Systems (ATS) and hiring managers\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "                ]\n",
    "        )\n",
    "\n",
    "    print(response.choices[0].message.content)\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6a046b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run the same prompt through:\n",
    "#Local LLM\n",
    "\n",
    "import ollama\n",
    "\n",
    "def summarize_resume_with_local_llm(resume_text):\n",
    "    prompt = f\"\"\"\n",
    "    Extract the following information from the resume text:\n",
    "    1. Candidate name\n",
    "    2. Years of experience\n",
    "    3. Skill set\n",
    "    4. Education summary\n",
    "    5. Generate a concise professional summary\n",
    "\n",
    "    Resume Text:\n",
    "    {resume_text}\n",
    "    \"\"\"\n",
    "    # Call the Ollama model with JSON format\n",
    "    response = local_llm_client = ollama.chat(\n",
    "        model=\"llama3\", \n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a resume optimization expert, specializing in authentic, strategic positioning of candidate experience.\"\n",
    "            \"   Your role is to analyze resumes against job descriptions to identify strengths, gaps, and keywords, ensuring content remains genuine and impactful for Applicant Tracking Systems (ATS) and hiring managers\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "        format=None\n",
    "    )\n",
    "\n",
    "    print(\"Local LLM Response:\")\n",
    "    print(response)\n",
    "    \n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8daef6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bonus: Create a ranking function that picks the “best-fit” candidate for a specific job description based on extracted data.\n",
    "\n",
    "def rank_candidate(resume_info, job_description):\n",
    "    input_text = f\"\"\"\n",
    "    Given the following resume information and job description, rate how well the candidate fits the job on a scale of 0 to 100.\n",
    "\n",
    "    Resume Information:\n",
    "    {resume_info}\n",
    "\n",
    "    Job Description:\n",
    "    {job_description}\n",
    "\n",
    "    Provide only the numerical score.\n",
    "    \"\"\"\n",
    "    response = client.responses.create(\n",
    "        model=\"gpt-5-nano\",\n",
    "        reasoning={\"effort\": \"minimal\"}, \n",
    "        input=input_text,\n",
    "        instructions=\"Rate candidate fit 0-100 based on resume and job description. Provide only the number.\"\n",
    "        #max_tokens=10\n",
    "    )\n",
    "    score_text = response.output_text.strip()\n",
    "    try:\n",
    "        score = float(score_text)\n",
    "    except ValueError:\n",
    "        score = 0.0\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a2c36211",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted Resume Text:\n",
      "Nirmala Kumar\n",
      "EXECUTIVE SUMMARY\n",
      "Transformational Product Leader and MIT-trained CTO with 20+ years of experience leading enterprise digital\n",
      "transformations and technical product delivery. Specialized in turning complex clinical and technical goals into\n",
      "reliable, scalable, compliant systems. Proven track record in architectural strategy and platform modernization\n",
      "for large-scale organizations (AT&T, Microsoft, Deloitte) and public sector entities. Currently Founder & CEO of\n",
      "SpeakEQ, leveraging hi\n",
      "Parsing with Ollama...\n",
      "Local LLM Response:\n",
      "model='llama3' created_at='2026-01-22T23:52:54.1842994Z' done=True done_reason='stop' total_duration=279686936700 load_duration=8082327500 prompt_eval_count=988 prompt_eval_duration=185419534100 eval_count=221 eval_duration=85895571200 message=Message(role='assistant', content=\"Based on the resume text, I extracted the following information:\\n\\n1. Candidate name: Nirmala Kumar\\n2. Years of experience: 20+ years\\n3. Skill set:\\n\\t* Product Strategy & Innovation\\n\\t* Architectural Strategy\\n\\t* Full-Cycle Delivery\\n\\t* High-Impact Leadership\\n\\t* Technical Product Management\\n\\t* Cloud-Native Frameworks\\n\\t* GitHub\\n\\t* CI/CD\\n\\t* Enterprise System Architecture\\n\\t* Technical Product Management (TPM)\\n4. Education summary:\\n\\t* Chief Technology Officer (CTO) Program, Massachusetts Institute of Technology\\n\\t* M.S Computer Science, East Tennessee University\\n\\nHere's a concise professional summary:\\n\\nTransformational product leader and MIT-trained CTO with 20+ years of experience driving enterprise digital transformations and technical product delivery. Proven track record in architectural strategy, platform modernization, and high-impact leadership. Skilled in product strategy, full-cycle delivery, and technical product management, with expertise in cloud-native frameworks, GitHub, CI/CD, and enterprise system architecture.\", thinking=None, images=None, tool_name=None, tool_calls=None) logprobs=None\n",
      "Parsing with GPT...\n",
      "1) Candidate name\n",
      "- Nirmala Kumar\n",
      "\n",
      "2) Years of experience\n",
      "- 20+ years\n",
      "\n",
      "3) Skill set\n",
      "- Strategic product leadership and vision development (defining North Star for complex high-tech products)\n",
      "- Architectural strategy and cloud-native platform modernization (HL7/FHIR, HIPAA/HITECH)\n",
      "- Full-cycle product delivery and SDLC management, including CI/CD automation\n",
      "- High-impact leadership and team mentorship, modernization of workflows\n",
      "- Technical product management for multi-billion-dollar platforms\n",
      "- HealthTech / EHR interoperability and data architecture\n",
      "- Compliance expertise (HIPAA, HITECH, SOC2, Securities Regulation)\n",
      "- Agile/Scrum leadership, program management, and release management\n",
      "- Enterprise system architecture, GitHub-driven workflows, and data governance\n",
      "- Stakeholder alignment with C-suite and public-sector requirements\n",
      "- Experience with cross-functional, high-visibility initiatives (e.g., Netbond, DirecTV, Entune)\n",
      "\n",
      "4) Education summary\n",
      "- Chief Technology Officer (CTO) Program, Massachusetts Institute of Technology (MIT)\n",
      "- Master of Science in Computer Science, East Tennessee University\n",
      "\n",
      "5) Concise professional summary\n",
      "MIT-trained executive technology leader with 20+ years guiding enterprise digital transformations and complex product delivery. Expert in cloud-native architectural strategy and health-tech interoperability (HL7/FHIR, HIPAA/HITECH), delivering scalable, compliant systems for large organizations. Founder & CEO of SpeakEQ, skilled at aligning engineering depth with C-suite objectives, reducing delivery risk, and maximizing long-term value in high-stakes environments.\n",
      "Candidate Fit Score: 78.0\n"
     ]
    }
   ],
   "source": [
    "# main function calling local llm \n",
    "import json\n",
    "\n",
    "resume_file_path = './data/resume.pdf'\n",
    "    \n",
    "# Check if the file exists before proceeding\n",
    "resume_text = extract_text_from_pdf(resume_file_path)\n",
    "print(\"Extracted Resume Text:\")\n",
    "print(resume_text[:500])  # Print first 500 characters of the resume text\n",
    "\n",
    "print(\"Parsing with Ollama...\")\n",
    "ollama_result = summarize_resume_with_local_llm(resume_text)\n",
    "\n",
    "print(\"Parsing with GPT...\")\n",
    "gpt_result = analyze_resume_using_gpt(resume_text)\n",
    "\n",
    "\n",
    "job_description = \"The Role: We’re looking for a Head of AI Product who thrives in a fast-moving, high-ownership environment. \" \\\n",
    "\"You’ll help shape Nimbus’s core platform—expanding how users capture data, train models, and deploy automated agents at scale. \" \\\n",
    "\"This is a hands-on, high-impact role: part product strategist, part operator, and part builder. \" \\\n",
    "\"You’ll work across customer feedback, internal teams, and go-to-market to ensure Nimbus evolves into the most powerful self-learning, white-label AI platform on the market. \" \\\n",
    "\"What You’ll Do: Own the core product roadmap — focusing on data capture, training workflows, and agent automation. \" \\\n",
    "\"Partner with engineering and design to define, ship, and iterate on high-leverage features. Drive platform extensibility — e\" \\\n",
    "\"nabling partners and customers to embed, customize, and resell agents. Optimize onboarding and training loops to make data capture and model improvement frictionless.\" \\\n",
    "\"Translate insights into action by setting KPIs, tracking adoption, and iterating based on real usage data.Bridge customer needs with technical realities, \" \\\n",
    "\"ensuring that what we build directly drives business outcomes.What We’re Looking For: 3–5+ years of product experience in SaaS or platform environments.\" \\\n",
    "\"Strong understanding of AI, data, or automation-driven products (LLMs, conversational AI, or workflow tools). \" \\\n",
    "\"Experience with partner or platform ecosystems (APIs, integrations, white-label products).Ability to create compelling product narratives—both visually and strategically.\" \\\n",
    "\"Technically conversant: comfortable working with APIs, webhooks, and developer-facing tools.Builder’s mindset: you move fast, embrace ambiguity, and balance vision with execution.\"\n",
    "\n",
    "score = rank_candidate(resume_text, job_description)\n",
    "print (f\"Candidate Fit Score: {score}\")\n",
    "\n",
    "# Save the result to a text file\n",
    "#with open(\"analysis_result.txt\", \"w\", encoding=\"utf-8\") as file:\n",
    "#    file.write(\"ollama_result: \\n\")\n",
    "#    file.write(ollama_resultchoices[0].message.content)\n",
    "#    file.write(\"\\n\\n\")\n",
    "#    file.write(\"gpt_result: \\n\")\n",
    "#    file.write(gpt_resultchoices[0].message.content)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
