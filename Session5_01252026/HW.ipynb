{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c90f22b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sentence_transformers\n",
    "from sentence_transformers import SentenceTransformer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b119b14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "def compute_sentence_similarity(sentence1, sentence2):\n",
    "    \"\"\"\n",
    "    Encodes two sentences using a pre-trained SBERT model and calculates \n",
    "    their cosine similarity.\n",
    "\n",
    "    Args:\n",
    "        sentence1 (str): The first sentence.\n",
    "        sentence2 (str): The second sentence.\n",
    "\n",
    "    Returns:\n",
    "        float: The cosine similarity score between the two sentences.\n",
    "    \"\"\"\n",
    "    # 1. Load the pre-trained SentenceTransformer model\n",
    "    # 'all-MiniLM-L6-v2' is a fast and efficient model\n",
    "    try:\n",
    "        model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading model: {e}\")\n",
    "        return None\n",
    "\n",
    "    # 2. Encode the sentences to get their embeddings (vector representations)\n",
    "    embeddings = model.encode([sentence1, sentence2])\n",
    "    #print(f\"emdeddings:{embeddings}\\n\")\n",
    "    \n",
    "    embedding_1 = embeddings[0].reshape(1, -1) # Reshape for sklearn\n",
    "    embedding_2 = embeddings[1].reshape(1, -1)\n",
    "\n",
    "\n",
    "    #print(f\"embedding_1:{embedding_1}\\n\")\n",
    "    #print(f\"embedding_2:{embedding_2}\") \n",
    "    \n",
    "    # 3. Compute the cosine similarity\n",
    "    # The result is an array, we take the first (and only) element\n",
    "    similarity_score = cosine_similarity(embedding_1, embedding_2)[0][0]\n",
    "\n",
    "    return similarity_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "41f215f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence A: 'The cat sat on the mat.'\n",
      "Sentence B: 'A feline rested on the rug.'\n",
      "Sentence C: 'I like to eat ice cream.'\n",
      "------------------------------\n",
      "Similarity (A vs. B): 0.5560\n",
      "Similarity (A vs. C): 0.0422\n",
      "Similarity (B vs. C): 0.0422\n",
      "\n",
      "As expected, sentences A and B are more similar in meaning.\n"
     ]
    }
   ],
   "source": [
    "# --- Example Usage ---\n",
    "sentence_a = \"The cat sat on the mat.\"\n",
    "sentence_b = \"A feline rested on the rug.\"\n",
    "sentence_c = \"I like to eat ice cream.\"\n",
    "\n",
    "similarity_ab = compute_sentence_similarity(sentence_a, sentence_b)\n",
    "similarity_ac = compute_sentence_similarity(sentence_a, sentence_c)\n",
    "similarity_bc = compute_sentence_similarity(sentence_b, sentence_c)\n",
    "\n",
    "print(f\"Sentence A: '{sentence_a}'\")\n",
    "print(f\"Sentence B: '{sentence_b}'\")\n",
    "print(f\"Sentence C: '{sentence_c}'\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "if similarity_ab is not None:\n",
    "    # Scores closer to 1 indicate higher similarity\n",
    "    print(f\"Similarity (A vs. B): {similarity_ab:.4f}\")\n",
    "    print(f\"Similarity (A vs. C): {similarity_ac:.4f}\")\n",
    "    print(f\"Similarity (B vs. C): {similarity_ac:.4f}\")\n",
    "\n",
    "    if similarity_ab > similarity_ac:\n",
    "        print(\"\\nAs expected, sentences A and B are more similar in meaning.\")\n",
    "    else:\n",
    "        print(\"\\nSomething unexpected happened.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b3083107",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a function that creates embeddings for each sentence in a text file and saves them as a CSV. How can I use the functionality in the app?\n",
    "\n",
    "#Text / Transcript\n",
    "#   ↓\n",
    "#Sentence Segmentation (regex)\n",
    "#   ↓\n",
    "#Batch Embeddings (OpenAI)\n",
    "#   ↓\n",
    "#CSV / Vector DB\n",
    "#   ↓\n",
    "#Coaching • Search • Analytics • XP\n",
    " \n",
    "import re\n",
    "import pandas as pd\n",
    "from typing import List\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "\n",
    "load_dotenv(override=True, dotenv_path=\"../.env.local\")\n",
    "my_api_key = os.getenv(\"OPEN_AI_API_KEY\")\n",
    "my_openai_client = OpenAI(api_key=my_api_key)\n",
    "\n",
    "# High-performance sentence splitter\n",
    "\n",
    "def split_sentences(text: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    Fast, production-grade sentence splitter using regex.\n",
    "    Handles most spoken transcript cases.\n",
    "    \"\"\"\n",
    "    sentences = re.split(r'(?<=[.!?])\\s+', text.strip())\n",
    "    return [s.strip() for s in sentences if len(s.strip()) > 3]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "26c2991e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Batched embedding generator\n",
    "def generate_embeddings(\n",
    "    sentences: List[str],\n",
    "    model: str = \"text-embedding-3-small\",\n",
    "    batch_size: int = 64\n",
    "):\n",
    "    \"\"\"\n",
    "    Generates embeddings in efficient batches.\n",
    "    \"\"\"\n",
    "    embeddings = []\n",
    "\n",
    "    for i in range(0, len(sentences), batch_size):\n",
    "        batch = sentences[i:i + batch_size]\n",
    "\n",
    "        response = my_openai_client.embeddings.create(\n",
    "            model=model,\n",
    "            input=batch\n",
    "        )\n",
    "\n",
    "        embeddings.extend([d.embedding for d in response.data])\n",
    "\n",
    "    return embeddings\n",
    "\n",
    "def process_file_to_csv(\n",
    "    input_file: str,\n",
    "    output_csv: str = \"sentence_embeddings.csv\"\n",
    "):\n",
    "    with open(input_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        text = f.read()\n",
    "\n",
    "    sentences = split_sentences(text)\n",
    "    embeddings = generate_embeddings(sentences)\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        \"sentence_id\": range(1, len(sentences) + 1),\n",
    "        \"sentence\": sentences,\n",
    "        \"embedding\": embeddings\n",
    "    })\n",
    "\n",
    "    df.to_csv(output_csv, index=False)\n",
    "    print(f\"Saved {len(sentences)} sentence embeddings → {output_csv}\")\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d2ee85f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 33 sentence embeddings → sentence_embeddings.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>What SpeakEQ Can Learn (and Improve On)\\n-----...</td>\n",
       "      <td>[0.022891094908118248, -0.011460373178124428, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Go Beyond Just Delivery, Focus on Emotional Al...</td>\n",
       "      <td>[0.03171725943684578, -0.015057769604027271, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Let’s realign that.”\\nThat’s a huge psychologi...</td>\n",
       "      <td>[-0.005456444341689348, 0.03932730481028557, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Anxiety Detection as a Core Feature\\nOrai assu...</td>\n",
       "      <td>[-0.012402944266796112, 0.017508376389741898, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>We identify it live, voice tremors, sudden pac...</td>\n",
       "      <td>[-0.016547979786992073, 0.054520245641469955, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>This will be life-changing for users with ADHD...</td>\n",
       "      <td>[0.006036007311195135, -0.006269796285778284, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Grammar Feedback in Spoken Context\\nThis compe...</td>\n",
       "      <td>[-0.0019025554647669196, 0.005172717850655317,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>We can analyze clarity, repetition, filler ove...</td>\n",
       "      <td>[0.0255295317620039, 0.03645041957497597, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Real-Time Emotional Coaching (Not Just Metrics...</td>\n",
       "      <td>[-0.01809908077120781, 0.009448678232729435, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Let’s slow the pace.</td>\n",
       "      <td>[0.046186890453100204, 0.026558153331279755, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>Try expressing more warmth now.”\\n5.</td>\n",
       "      <td>[0.014768900349736214, -0.007605151738971472, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>Personalized, Therapeutic Tone\\nOrai’s tone is...</td>\n",
       "      <td>[0.051264483481645584, -0.018466388806700706, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>Brand Identity That Reflects Compassion\\nInste...</td>\n",
       "      <td>[0.08356939256191254, -0.01538184192031622, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>Depth &gt; Volume in Content Strategy\\nRather tha...</td>\n",
       "      <td>[0.03310035541653633, 0.022479847073554993, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>Fix known frustrations in Orai (bugs, crashes,...</td>\n",
       "      <td>[0.0078031872399151325, -0.00742094311863184, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>Bug-Free, Reliable Experience\\n Prioritize sta...</td>\n",
       "      <td>[0.026900826022028923, 0.025471089407801628, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>“Works reliably” is still a USP.</td>\n",
       "      <td>[-0.04909947142004967, 0.04152394458651543, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>Transparent Free Tier\\n Offer a functional fre...</td>\n",
       "      <td>[-0.009617661125957966, 0.011431518010795116, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>Localized Payment Options\\n Integrate UPI, M-P...</td>\n",
       "      <td>[0.004544478375464678, -0.03854652866721153, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>Consider educational pricing tiers.</td>\n",
       "      <td>[-0.015999287366867065, -0.020246632397174835,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>Richer &amp; Growing Content Library\\n Include wee...</td>\n",
       "      <td>[-0.0164733175188303, -0.034638412296772, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>Real Coaching Layer\\n Allow users to book shor...</td>\n",
       "      <td>[-0.04551786184310913, 0.009729227982461452, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>Detailed Progress Insights\\n Visualize pace va...</td>\n",
       "      <td>[0.010877604596316814, 0.014486796222627163, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>Repetitive Content\\nSeveral reviews mentioned ...</td>\n",
       "      <td>[0.0042284210212528706, 0.022424224764108658, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>It starts to feel monotonous, especially to re...</td>\n",
       "      <td>[0.011133214458823204, -0.005803569220006466, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>Lack of Depth in Some Areas\\nSome users feel t...</td>\n",
       "      <td>[-0.04135364294052124, 0.007334086578339338, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>No Quantified Progress Tracking\\nUsers want pe...</td>\n",
       "      <td>[0.019779501482844353, 0.053516313433647156, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>They want something beyond “great job” ,  they...</td>\n",
       "      <td>[0.011643066070973873, 0.029289240017533302, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>Limited Motivation Features\\nWhile some gamifi...</td>\n",
       "      <td>[-0.0007029026746749878, 0.022036388516426086,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>Accuracy of AI Feedback (Mild Doubts)\\nA few u...</td>\n",
       "      <td>[-0.015938276425004005, 0.012536324560642242, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>31</td>\n",
       "      <td>This introduces a small element of distrust or...</td>\n",
       "      <td>[0.021663077175617218, -0.012822690419852734, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>32</td>\n",
       "      <td>Too Much Focus on Anxiety/Calming\\nOne user sa...</td>\n",
       "      <td>[0.005913612898439169, -0.023974696174263954, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>33</td>\n",
       "      <td>No Industry-Specific Modules\\nUsers want tailo...</td>\n",
       "      <td>[-0.049656543880701065, -0.0019804134499281645...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    sentence_id                                           sentence  \\\n",
       "0             1  What SpeakEQ Can Learn (and Improve On)\\n-----...   \n",
       "1             2  Go Beyond Just Delivery, Focus on Emotional Al...   \n",
       "2             3  Let’s realign that.”\\nThat’s a huge psychologi...   \n",
       "3             4  Anxiety Detection as a Core Feature\\nOrai assu...   \n",
       "4             5  We identify it live, voice tremors, sudden pac...   \n",
       "5             6  This will be life-changing for users with ADHD...   \n",
       "6             7  Grammar Feedback in Spoken Context\\nThis compe...   \n",
       "7             8  We can analyze clarity, repetition, filler ove...   \n",
       "8             9  Real-Time Emotional Coaching (Not Just Metrics...   \n",
       "9            10                               Let’s slow the pace.   \n",
       "10           11               Try expressing more warmth now.”\\n5.   \n",
       "11           12  Personalized, Therapeutic Tone\\nOrai’s tone is...   \n",
       "12           13  Brand Identity That Reflects Compassion\\nInste...   \n",
       "13           14  Depth > Volume in Content Strategy\\nRather tha...   \n",
       "14           15  Fix known frustrations in Orai (bugs, crashes,...   \n",
       "15           16  Bug-Free, Reliable Experience\\n Prioritize sta...   \n",
       "16           17                   “Works reliably” is still a USP.   \n",
       "17           18  Transparent Free Tier\\n Offer a functional fre...   \n",
       "18           19  Localized Payment Options\\n Integrate UPI, M-P...   \n",
       "19           20                Consider educational pricing tiers.   \n",
       "20           21  Richer & Growing Content Library\\n Include wee...   \n",
       "21           22  Real Coaching Layer\\n Allow users to book shor...   \n",
       "22           23  Detailed Progress Insights\\n Visualize pace va...   \n",
       "23           24  Repetitive Content\\nSeveral reviews mentioned ...   \n",
       "24           25  It starts to feel monotonous, especially to re...   \n",
       "25           26  Lack of Depth in Some Areas\\nSome users feel t...   \n",
       "26           27  No Quantified Progress Tracking\\nUsers want pe...   \n",
       "27           28  They want something beyond “great job” ,  they...   \n",
       "28           29  Limited Motivation Features\\nWhile some gamifi...   \n",
       "29           30  Accuracy of AI Feedback (Mild Doubts)\\nA few u...   \n",
       "30           31  This introduces a small element of distrust or...   \n",
       "31           32  Too Much Focus on Anxiety/Calming\\nOne user sa...   \n",
       "32           33  No Industry-Specific Modules\\nUsers want tailo...   \n",
       "\n",
       "                                            embedding  \n",
       "0   [0.022891094908118248, -0.011460373178124428, ...  \n",
       "1   [0.03171725943684578, -0.015057769604027271, -...  \n",
       "2   [-0.005456444341689348, 0.03932730481028557, 0...  \n",
       "3   [-0.012402944266796112, 0.017508376389741898, ...  \n",
       "4   [-0.016547979786992073, 0.054520245641469955, ...  \n",
       "5   [0.006036007311195135, -0.006269796285778284, ...  \n",
       "6   [-0.0019025554647669196, 0.005172717850655317,...  \n",
       "7   [0.0255295317620039, 0.03645041957497597, -0.0...  \n",
       "8   [-0.01809908077120781, 0.009448678232729435, -...  \n",
       "9   [0.046186890453100204, 0.026558153331279755, -...  \n",
       "10  [0.014768900349736214, -0.007605151738971472, ...  \n",
       "11  [0.051264483481645584, -0.018466388806700706, ...  \n",
       "12  [0.08356939256191254, -0.01538184192031622, -0...  \n",
       "13  [0.03310035541653633, 0.022479847073554993, 0....  \n",
       "14  [0.0078031872399151325, -0.00742094311863184, ...  \n",
       "15  [0.026900826022028923, 0.025471089407801628, 0...  \n",
       "16  [-0.04909947142004967, 0.04152394458651543, -0...  \n",
       "17  [-0.009617661125957966, 0.011431518010795116, ...  \n",
       "18  [0.004544478375464678, -0.03854652866721153, 0...  \n",
       "19  [-0.015999287366867065, -0.020246632397174835,...  \n",
       "20  [-0.0164733175188303, -0.034638412296772, -0.0...  \n",
       "21  [-0.04551786184310913, 0.009729227982461452, 0...  \n",
       "22  [0.010877604596316814, 0.014486796222627163, 0...  \n",
       "23  [0.0042284210212528706, 0.022424224764108658, ...  \n",
       "24  [0.011133214458823204, -0.005803569220006466, ...  \n",
       "25  [-0.04135364294052124, 0.007334086578339338, 0...  \n",
       "26  [0.019779501482844353, 0.053516313433647156, 0...  \n",
       "27  [0.011643066070973873, 0.029289240017533302, -...  \n",
       "28  [-0.0007029026746749878, 0.022036388516426086,...  \n",
       "29  [-0.015938276425004005, 0.012536324560642242, ...  \n",
       "30  [0.021663077175617218, -0.012822690419852734, ...  \n",
       "31  [0.005913612898439169, -0.023974696174263954, ...  \n",
       "32  [-0.049656543880701065, -0.0019804134499281645...  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process_file_to_csv(\"./What_SpeakEQ_Can_Learn.txt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
